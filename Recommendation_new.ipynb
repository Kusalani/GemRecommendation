{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD39JgveFb9Y"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knJ8wNE_A_fI",
        "outputId": "93d7f3a4-1838-4c59-dd16-0da6f618a398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: torchvision==0.14.1 in /usr/local/lib/python3.10/dist-packages (0.14.1)\n",
            "Requirement already satisfied: torchaudio==0.13.1 in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.7.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.41.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5l3o1-tBHzR",
        "outputId": "3ae3dc07-c2c1-4a30-be35-76bfa68d7063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snI8re2rBKgZ",
        "outputId": "dcc4fd57-b819-428e-b11b-ef2d07a1aef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GDtmgMSBOJI",
        "outputId": "6c0490a2-51a2-4de5-b7c4-8d3ebf124189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.41.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHAHa1KCf6iT"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer, TrainingArguments, Trainer, DefaultDataCollator\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pickle\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjQt-3r7A7qK",
        "outputId": "9714a952-f6ad-4572-8217-caaa1ae24a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Cq9b3OA7qL",
        "outputId": "07433ee8-f419-430c-d3cd-02b7200adc4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FYXD95LFst1"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sX8pWVABQfN",
        "outputId": "8acf2243-063a-4917-c6b6-9358f49174a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CmTr2x_DAi8",
        "outputId": "91054fad-e305-4c31-a9f8-cc2c6dc373d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/data1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAIyxmLTf6iV"
      },
      "outputs": [],
      "source": [
        "model_card = \"distilbert-base-uncased\"\n",
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6tcTz3lF0q4"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVJZ8Vdxf6iW",
        "outputId": "be4dff69-21ee-4888-8f4c-84d41375b97e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForQuestionAnswering(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_card)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOnDxoaPm9DJ"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0BANC-cf6iW"
      },
      "outputs": [],
      "source": [
        "def create_dataset(data_path = '/content/drive/MyDrive/data1/gems.json'):\n",
        "    with open(data_path) as f:\n",
        "        data = json.load(f)\n",
        "    dataset = {}\n",
        "    dataset['id'] = []\n",
        "    dataset['title'] = []\n",
        "    dataset['context'] = []\n",
        "    dataset['question'] = []\n",
        "    dataset['answers'] = []\n",
        "    for d in data['data']:\n",
        "        d = d['paragraphs'][0]\n",
        "        for qa in d['qas']:\n",
        "            context = d['context']\n",
        "            question = qa['question']\n",
        "            answer = qa['answers'][0]\n",
        "\n",
        "            answer_start = answer['answer_start']\n",
        "            answer_end = answer['answer_end']\n",
        "            text = answer['text']\n",
        "            answer = {\n",
        "                    'answer_start': [answer_start],\n",
        "                    'answer_end': [answer_end],\n",
        "                    'text': [text]\n",
        "                    }\n",
        "            id_ = qa['id']\n",
        "            title = 'gem-qna'\n",
        "\n",
        "            dataset['id'].append(id_)\n",
        "            dataset['title'].append(title)\n",
        "            dataset['context'].append(context)\n",
        "            dataset['question'].append(question)\n",
        "            dataset['answers'].append(answer)\n",
        "\n",
        "    dataset = Dataset.from_dict(dataset)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6ybbU0Rf6iW"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "                    questions,\n",
        "                    examples[\"context\"],\n",
        "                    max_length=384,\n",
        "                    truncation=\"only_second\",\n",
        "                    return_offsets_mapping=True,\n",
        "                    padding=\"max_length\",\n",
        "                    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    inputs[\"offset_mapping\"] = offset_mapping\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "04113e72a9d04b10ab6743fc80742043",
            "61c1cec100f6439591d4c0718a29d10c",
            "a88d0e4bdcf941e0ae8c1e6f3c150f63",
            "72643bc733e84722a29cfc1b5860b2a4",
            "2f61b6c2e673417980b3ce6183033ae0",
            "cb7e677d201a4159827032c35f034ee7",
            "266ef79eca2b47d78aba862e1be14597",
            "722e8dc4e9f340aba7c939d199c69edc",
            "ac61f17347b0420db78389daa8a9280e",
            "0c6995f2a18544319fc6087239a35c6d",
            "f94c44ef1063488ea6eb1ec727c800ea"
          ]
        },
        "id": "HJIjrPY5f6iX",
        "outputId": "35a21f8b-d3d6-432c-ec4d-ff4b852caca4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04113e72a9d04b10ab6743fc80742043",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2982 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = create_dataset()\n",
        "dataset_processed = dataset.map(\n",
        "                                preprocess_function,\n",
        "                                remove_columns = dataset.column_names,\n",
        "                                batched=True\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFE_AGI9f6iX"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "                                warmup_steps=500,\n",
        "                                weight_decay=0.01,\n",
        "                                logging_steps=500,\n",
        "                                learning_rate=2e-5,\n",
        "                                output_dir=\"models/gem-qna\",\n",
        "                                num_train_epochs=100,\n",
        "                                save_strategy=\"epoch\",\n",
        "                                per_device_train_batch_size=10,\n",
        "                                )\n",
        "trainer = Trainer(\n",
        "                model=model,\n",
        "                args=training_args,\n",
        "                tokenizer=tokenizer,\n",
        "                train_dataset=dataset_processed,\n",
        "                data_collator=data_collator,\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yppfcCjPx_Xf",
        "outputId": "032b3881-abaf-46cb-e316-5948d726601e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "iQzziNXuxpWA",
        "outputId": "83e08bbe-35ed-49ae-acd0-81f4b82dfa45"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='29900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   70/29900 29:12 < 213:31:32, 0.04 it/s, Epoch 0.23/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/data1/models/gem-qna-v6'):\n",
        "  trainer.train()\n",
        "  # save the model\n",
        "  trainer.save_model('/content/drive/MyDrive/data1/models/gem-qna-v6')\n",
        "\n",
        "model = '/content/drive/MyDrive/data1/models/gem-qna-v6'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnHHjVgUf6iY"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlubeHT9f6iY",
        "outputId": "31214ccc-19a7-44da-de57-cb5ed0fb95dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file models/gem-qna\\config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"models/gem-qna\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file models/gem-qna\\config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"models/gem-qna\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file models/gem-qna\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForQuestionAnswering.\n",
            "\n",
            "All the weights of DistilBertForQuestionAnswering were initialized from the model checkpoint at models/gem-qna.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n",
            "loading file vocab.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n"
          ]
        }
      ],
      "source": [
        "# load the model from pipeline\n",
        "qa_pipeline = pipeline(\n",
        "                        \"question-answering\",\n",
        "                        model=\"models/gem-qna-v6\",\n",
        "                        device = -1\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jtT6gAZzNPL"
      },
      "outputs": [],
      "source": [
        "def get_context(question):\n",
        "    with open('data/gems.json') as f:\n",
        "        data = json.load(f)\n",
        "        #context = None\n",
        "        for item in data[\"data\"]:\n",
        "            for paragraph in item[\"paragraphs\"]:\n",
        "                for qa in paragraph[\"qas\"]:\n",
        "                    if qa[\"question\"] == question:\n",
        "                        context = paragraph[\"context\"]\n",
        "                        context\n",
        "                        return context\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAUXDvtMA7qO",
        "outputId": "b33eae89-e957-463a-ff8a-98e8e9a3a110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (2.10.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.13.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
            "Collecting tensorflow-intel==2.13.0\n",
            "  Downloading tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl (276.5 MB)\n",
            "     -------------------------------------- 276.5/276.5 MB 1.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
            "  Downloading protobuf-4.24.0-cp38-cp38-win_amd64.whl (430 kB)\n",
            "     -------------------------------------- 430.6/430.6 kB 1.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: setuptools in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (66.0.0)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.9)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
            "Collecting keras<2.14,>=2.13.1\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "     ---------------------------------------- 1.7/1.7 MB 1.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.54.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
            "Collecting tensorboard<2.14,>=2.13\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "     ---------------------------------------- 5.6/5.6 MB 1.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "     -------------------------------------- 440.8/440.8 kB 1.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.18.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.3)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: urllib3<2.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.1\n",
            "    Uninstalling typing_extensions-4.6.1:\n",
            "      Successfully uninstalled typing_extensions-4.6.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.10.0\n",
            "    Uninstalling tensorflow-estimator-2.10.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.10.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.6.1\n",
            "    Uninstalling tensorboard-data-server-0.6.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'D:\\\\anaconda3\\\\envs\\\\myenv\\\\Lib\\\\site-packages\\\\google\\\\~rotobuf\\\\internal\\\\_api_implementation.cp38-win_amd64.pyd'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (0.13.0)\n",
            "Collecting tensorflow-hub\n",
            "  Downloading tensorflow_hub-0.14.0-py2.py3-none-any.whl (90 kB)\n",
            "     ---------------------------------------- 90.3/90.3 kB 1.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: protobuf>=3.19.6 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-hub) (4.24.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in d:\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorflow-hub) (1.24.3)\n",
            "Installing collected packages: tensorflow-hub\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.13.0\n",
            "    Uninstalling tensorflow-hub-0.13.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.13.0\n",
            "Successfully installed tensorflow-hub-0.14.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
            "    WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda3\\envs\\myenv\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda3\\envs\\myenv\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade tensorflow\n",
        "%pip install --upgrade tensorflow-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6rApCA1A7qP"
      },
      "outputs": [],
      "source": [
        "# Load the Universal Sentence Encoder's TF Hub module\n",
        "import tensorflow_hub as hub\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = hub.load(module_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxxdpTcSA7qP"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_json('data/gems.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQvKmo04A7qP"
      },
      "outputs": [],
      "source": [
        "questions = []\n",
        "for data_entry in dataset[\"data\"]:\n",
        "    for paragraph in data_entry[\"paragraphs\"]:\n",
        "        for qa in paragraph[\"qas\"]:\n",
        "            questions.append(qa[\"question\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACfAkppPA7qP"
      },
      "outputs": [],
      "source": [
        "# Compute a representation for each question\n",
        "question_embeddings = model(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyE20B8TA7qP"
      },
      "outputs": [],
      "source": [
        "# Define a function to find the most similar question\n",
        "def find_similar_question(query):\n",
        "    query_embedding = model([query])[0]\n",
        "    similarities = np.inner(question_embeddings, query_embedding)\n",
        "    closest = np.argmax(similarities, axis=0)\n",
        "    return questions[closest]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLuc-kxTA7qP"
      },
      "outputs": [],
      "source": [
        "# User input\n",
        "user_input = \"What are the gemstones suitable for new mothers?\"\n",
        "\n",
        "# Find and print the most similar question\n",
        "similar_question = find_similar_question(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhGM-jVMf6iY",
        "outputId": "590029a4-0fa7-4c45-9d94-9b49681f4fdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.9999986886978149, 'start': 0, 'end': 11, 'answer': 'Rose Quartz'}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Use the loaded model for prediction\n",
        "\n",
        "context = get_context(similar_question)\n",
        "qa_pipeline(question = similar_question, context = context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7zDnQzeA7qP"
      },
      "source": [
        "================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNMtnjUvA7qQ",
        "outputId": "fe2f5e88-7ffe-4d1b-ed13-073a75b712cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exact Match (EM) on the dataset: 35.70%\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have already loaded the dataset and created the qa_pipeline\n",
        "# using the code you provided earlier\n",
        "\n",
        "def calculate_exact_match(dataset):\n",
        "    num_correct = 0\n",
        "    total_examples = len(dataset)\n",
        "\n",
        "    for i in range(total_examples):\n",
        "        question = dataset[\"data\"][i][\"paragraphs\"][0][\"qas\"][0][\"question\"]\n",
        "        ground_truth_answer = dataset[\"data\"][i][\"paragraphs\"][0][\"qas\"][0][\"answers\"][0][\"text\"]\n",
        "        context = get_context(question)\n",
        "\n",
        "        # Get the predicted answer from the pipeline\n",
        "        prediction = qa_pipeline(question=question, context=context)\n",
        "\n",
        "        # Extract the predicted answer text\n",
        "        predicted_answer = prediction[\"answer\"]\n",
        "\n",
        "        # Calculate Exact Match\n",
        "        if predicted_answer == ground_truth_answer:\n",
        "            num_correct += 1\n",
        "\n",
        "    exact_match = num_correct / total_examples\n",
        "    return exact_match\n",
        "\n",
        "# Call the function to calculate Exact Match\n",
        "dataset = pd.read_json('data/gems.json')\n",
        "exact_match = calculate_exact_match(dataset)\n",
        "\n",
        "print(\"Exact Match (EM) on the dataset: {:.2%}\".format(exact_match))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REvTbhqoA7qQ",
        "outputId": "eeb5aa67-4676-4edd-f150-6ded55a9f472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score on the dataset: 46.57%\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have already loaded the dataset and created the qa_pipeline\n",
        "# using the code you provided earlier\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def calculate_f1_score(dataset):\n",
        "    total_f1 = 0\n",
        "    total_examples = len(dataset)\n",
        "\n",
        "    for i in range(total_examples):\n",
        "        question = dataset[\"data\"][i][\"paragraphs\"][0][\"qas\"][0][\"question\"]\n",
        "        ground_truth_answer = dataset[\"data\"][i][\"paragraphs\"][0][\"qas\"][0][\"answers\"][0][\"text\"]\n",
        "        context = get_context(question)\n",
        "\n",
        "        # Get the predicted answer from the pipeline\n",
        "        prediction = qa_pipeline(question=question, context=context)\n",
        "\n",
        "        # Extract the predicted answer text\n",
        "        predicted_answer = prediction[\"answer\"]\n",
        "\n",
        "        # Calculate F1 score\n",
        "        f1 = compute_f1(predicted_answer, ground_truth_answer)\n",
        "        total_f1 += f1\n",
        "\n",
        "    avg_f1 = total_f1 / total_examples\n",
        "    return avg_f1\n",
        "\n",
        "def compute_f1(pred_answer, ground_truth):\n",
        "    common = Counter(pred_answer.split()) & Counter(ground_truth.split())\n",
        "    num_same = sum(common.values())\n",
        "\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "\n",
        "    precision = 1.0 * num_same / len(pred_answer.split())\n",
        "    recall = 1.0 * num_same / len(ground_truth.split())\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "# Call the function to calculate F1 score\n",
        "dataset = pd.read_json('data/gems.json')\n",
        "f1_score = calculate_f1_score(dataset)\n",
        "\n",
        "print(\"F1 Score on the dataset: {:.2%}\".format(f1_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuIe4XFcA7qR"
      },
      "outputs": [],
      "source": [
        "# Initialize counters for EM and F1 scores\n",
        "total_cases = len(user_inputs)\n",
        "em_matches = 0\n",
        "total_precision = 0\n",
        "total_recall = 0\n",
        "\n",
        "for i in range(total_cases):\n",
        "    user_input = user_inputs[i]\n",
        "    ground_truth_answer = ground_truth_answers[i]\n",
        "    predicted_answer = predict_answer(user_input)  # Use your QA model to predict the answer\n",
        "\n",
        "    # Calculate EM score\n",
        "    if predicted_answer == ground_truth_answer:\n",
        "        em_matches += 1\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    true_positive = int(predicted_answer == ground_truth_answer)\n",
        "    false_positive = int(predicted_answer != ground_truth_answer)\n",
        "    false_negative = int(predicted_answer != ground_truth_answer)\n",
        "\n",
        "    precision = true_positive / (true_positive + false_positive)\n",
        "    recall = true_positive / (true_positive + false_negative)\n",
        "\n",
        "    total_precision += precision\n",
        "    total_recall += recall\n",
        "\n",
        "# Calculate EM score\n",
        "em_score = em_matches / total_cases\n",
        "\n",
        "# Calculate average precision and recall\n",
        "average_precision = total_precision / total_cases\n",
        "average_recall = total_recall / total_cases\n",
        "\n",
        "# Calculate F1 score\n",
        "f1_score = 2 * (average_precision * average_recall) / (average_precision + average_recall)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbUTaUTbA7qR"
      },
      "source": [
        "-----------"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04113e72a9d04b10ab6743fc80742043": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61c1cec100f6439591d4c0718a29d10c",
              "IPY_MODEL_a88d0e4bdcf941e0ae8c1e6f3c150f63",
              "IPY_MODEL_72643bc733e84722a29cfc1b5860b2a4"
            ],
            "layout": "IPY_MODEL_2f61b6c2e673417980b3ce6183033ae0"
          }
        },
        "0c6995f2a18544319fc6087239a35c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266ef79eca2b47d78aba862e1be14597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f61b6c2e673417980b3ce6183033ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c1cec100f6439591d4c0718a29d10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb7e677d201a4159827032c35f034ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_266ef79eca2b47d78aba862e1be14597",
            "value": "Map: 100%"
          }
        },
        "722e8dc4e9f340aba7c939d199c69edc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72643bc733e84722a29cfc1b5860b2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c6995f2a18544319fc6087239a35c6d",
            "placeholder": "​",
            "style": "IPY_MODEL_f94c44ef1063488ea6eb1ec727c800ea",
            "value": " 2982/2982 [00:02&lt;00:00, 1389.18 examples/s]"
          }
        },
        "a88d0e4bdcf941e0ae8c1e6f3c150f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_722e8dc4e9f340aba7c939d199c69edc",
            "max": 2982,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac61f17347b0420db78389daa8a9280e",
            "value": 2982
          }
        },
        "ac61f17347b0420db78389daa8a9280e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb7e677d201a4159827032c35f034ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f94c44ef1063488ea6eb1ec727c800ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}